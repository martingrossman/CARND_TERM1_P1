{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** \n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The tools you have are color selection, region of interest selection, grayscaling, Gaussian smoothing, Canny Edge Detection and Hough Tranform line detection.  You  are also free to explore and try other techniques that were not presented in the lesson.  Your goal is piece together a pipeline to detect the line segments in the image, then average/extrapolate them and draw them onto the image for display (as below).  Once you have a working pipeline, try it out on the video stream below.**\n",
    "\n",
    "---\n",
    "\n",
    "<figure>\n",
    " <img src=\"examples/line-segments-example.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output should look something like this (above) after detecting line segments using the helper functions below </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n",
    "<figure>\n",
    " <img src=\"examples/laneLines_thirdPass.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your goal is to connect/average/extrapolate line segments to get output like this</p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# officialpackages\n",
    "import matplotlib.image as mpimg\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "# project packages\n",
    "from HELPERS import helper_funs as hf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in an Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and create pathes to files\n",
    "test_images_dir = 'test_images/'\n",
    "test_videos_dir = 'test_videos'\n",
    "test_images_fullpath_list = hf.dir_content_fullpath_lst(test_images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas for Lane Detection Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions stored in HELPERS in helper_funs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_detection(printProcess=True):\n",
    "    # PrintProcess == False -> make videos otherwise plot process pipeline\n",
    "    \n",
    "    # Parameters \n",
    "    canny_low = 100\n",
    "    canny_high = 200\n",
    "    gbsize = 7\n",
    "    if gbsize%2 == 0:\n",
    "\n",
    "        print('gbsize is',gbsize,', change to odd number!')\n",
    "        gbsize = gbsize + 1\n",
    "    hough_rho = 1\n",
    "    hough_theta = np.pi / 90\n",
    "    hough_threshold = 10\n",
    "    hough_min_line_length = 70\n",
    "    hough_max_line_gap = 200\n",
    "\n",
    "    # Global vars\n",
    "    # line previous serves for low pass filter as memory\n",
    "    global lines_previous\n",
    "    lines_previous = np.array([])\n",
    "    global counter\n",
    "    counter = 0\n",
    "\n",
    "    # orderd dictionary filters_funs_d accomodate image processing filters\n",
    "    # add image processing filters to create ordered pipeline as ordered dict\n",
    "    # for each filter add parameters into dictionary as tuples\n",
    "    # needs to be ordered to fix the order (no need in 3.6 up)\n",
    "    # 'none' = no params, image = speacial treatment - use image as parameter\n",
    "    filters_funs_d = OrderedDict()\n",
    "    filters_funs_d[hf.select_white_yellow_L] = 'none'\n",
    "    filters_funs_d[hf.grayscale] = 'none'\n",
    "    filters_funs_d[hf.gaussian_blur] = (gbsize,)  # needs to be tuple ()\n",
    "    filters_funs_d[hf.canny] = (canny_low, canny_high)\n",
    "    filters_funs_d[hf.region_of_interest] = 'none'\n",
    "\n",
    "\n",
    "    if printProcess:\n",
    "        # if printing process add Hough + Weightning into dictionary of filters\n",
    "        filters_funs_d[hf.hough_lines] = (hough_rho, hough_theta, hough_threshold,\n",
    "                                          hough_min_line_length, hough_max_line_gap, lines_previous, counter)\n",
    "\n",
    "        filters_funs_d[hf.weighted_img] = 'image'\n",
    "\n",
    "        # create image list \n",
    "        image_list = [mpimg.imread(test_images_fullpath_list[idx])\n",
    "                      for idx, image_file in enumerate(test_images_fullpath_list)]\n",
    "        # create image names list\n",
    "        image_name_list = [str(test_images_fullpath_list[idx]).split('/')[1]\n",
    "                           for idx, image_file in enumerate(test_images_fullpath_list)]\n",
    "\n",
    "        # Processing\n",
    "        # For each image in image list run process_filters() to apply filters in pipeline\n",
    "        processed_images_lst = [hf.process_filters(image, image_name, filters_funs_d)\n",
    "                                for image, image_name in zip(image_list, image_name_list)]\n",
    "\n",
    "        b = (0, 1, 2, 3, 4, 5, 6, 7)  # select which filter to plot (0-7)\n",
    "        processed_images_lst_sel = [itemgetter(*b)(sublist) for sublist in processed_images_lst]\n",
    "        hf.plot_pipes(processed_images_lst_sel, fgs=(20, 15))\n",
    "\n",
    "    def process_pipeline0(img):\n",
    "        global counter\n",
    "        counter = counter + 1\n",
    "        global lines_previous\n",
    "\n",
    "        image = img\n",
    "        \n",
    "        # apply image processing filters defined in filters_funs_d except hough_lines and weighted image\n",
    "        # hough_lines uses global memory previous line to filter the lanes\n",
    "        im = hf.process_filters(img, 'none', filters_funs_d)\n",
    "        masked_img = im[-1][0]\n",
    "\n",
    "        hough_img, lines_raw, lines_new = hf.hough_lines(masked_img, hough_rho, hough_theta, hough_threshold,\n",
    "                                                         hough_min_line_length, hough_max_line_gap, lines_previous,counter)\n",
    "        result = hf.weighted_img(hough_img, image)\n",
    "        lines_previous = lines_new\n",
    "\n",
    "        return result\n",
    "\n",
    "    # function to process video\n",
    "    def process_video(video_in_path, video_out_path, pipeline, show_video=False):\n",
    "        global counter\n",
    "        counter = 0\n",
    "\n",
    "\n",
    "        clip_in = VideoFileClip(video_in_path)\n",
    "        \n",
    "        clip_frame = clip_in.fl_image(pipeline)\n",
    "        clip_frame.write_videofile(video_out_path, audio=False)\n",
    "        \n",
    "        clip_in.reader.close()\n",
    "        clip_frame.reader.close()\n",
    "        if show_video :\n",
    "            return(\n",
    "            HTML(\"\"\"\n",
    "            <video width=\"960\" height=\"540\" controls>\n",
    "              <source src=\"{0}\">\n",
    "            </video>\n",
    "            \"\"\".format(video_out_path)))\n",
    "\n",
    "        lines_previous = np.array([])\n",
    "\n",
    "\n",
    "    if not printProcess:\n",
    "\n",
    "        process_video('test_videos/solidYellowLeft.mp4', \"test_videos_output/solidYellowLeft.mp4\", process_pipeline0)\n",
    "        process_video('test_videos/solidWhiteRight.mp4', \"test_videos_output/solidWhiteRight.mp4\", process_pipeline0)\n",
    "        process_video('test_videos/challenge.mp4', \"test_videos_output/challenge.mp4\", process_pipeline0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing Pipline Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image processing is based on :\n",
    "1. reading image from movie frame\n",
    "2. selecting only white and yellow colors (line colors)\n",
    "3. conversion to grayscale\n",
    "4. gaussian blur\n",
    "5. canny edge detection\n",
    "6. selecting only region of interest\n",
    "7. hough lines - detecting lines at image\n",
    " * hough transform - detection of all straight lines\n",
    " * sorting into left, right lines\n",
    " * checking for min, max slope\n",
    " * averaging separate left and right lines\n",
    " * averaging resuting lines with previos lines from last frame\n",
    " * drawing lines on black image\n",
    "8. weighted image between hough lines and movie frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_detection(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video processing + Optional Challange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process movie  printProcess = False \n",
    "\n",
    "lane_detection(printProcess=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.show_videos_html(\"test_videos_output/solidYellowLeft.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.show_videos_html(\"test_videos_output/solidWhiteRight.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.show_videos_html(\"test_videos_output/challenge.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writeup and Submission\n",
    "\n",
    "If you're satisfied with your video outputs, it's time to make the report writeup in a pdf or markdown file. Once you have this Ipython notebook ready along with the writeup, it's time to submit for review! Here is a [link](https://github.com/udacity/CarND-LaneLines-P1/blob/master/writeup_template.md) to the writeup template file.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
